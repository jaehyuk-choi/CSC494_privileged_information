# Leveraging LLMs to Generate Privileged Information for Clinical Predictive Tasks

This repository accompanies the research project **"Leveraging LLMs to Generate Privileged Information for Clinical Predictive Tasks"** by **David Pellow and Jaehyuk Choi**. The project explores how privileged information generated by large language models (LLMs) can enhance predictive modeling in healthcare by generating synthetic, context-rich auxiliary data used only during training.

---

## 📌 Overview

Predictive modeling in clinical settings is often limited by small, imbalanced datasets. Rather than using LLMs as direct predictors, this project investigates their utility in generating **privileged information** — synthetic features used exclusively at training time.

---

## ⚙️ Methodology

1. **Synthetic Data Generation**  
   LLMs (LLaMA-8B, LLaMA-70B) are prompted to simulate clinical reasoning and generate side information.

2. **Pattern-Based Integration**  
   LLM-generated data is integrated through four training paradigms:

   - **Direct**  
     The LLM-generated scalar value (e.g., predicted HbA1c) is directly appended to the input feature vector during training.
   - **Multi-task**  
     The model is trained to solve the main classification task along with multiple auxiliary tasks using LLM-generated labels (e.g., `health_1_10`, `diabetes_risk_score`, `has_diabetes`). These tasks share a common encoder, enabling richer representation learning.
   - **Multi-view**  
     The original clinical features (view1) and LLM-generated side information (view2) are processed separately, simulating a multi-view learning scenario.
   - **Pairwise similarity**  
     The LLM is prompted to generate similarity scores between patient pairs. These scores guide the model to learn instance-level relationships through pairwise inputs (e.g., patient A is more similar to patient B than to patient C).
   - Hybrid strategies (e.g., Direct + Multi-task) are also implemented.

3. **Training & Evaluation**  
   Models are trained using various strategies including:
   - Simultaneous training
   - Decoupled training
   - Pretrained then Finetuned training

---

## 🧪 Datasets

- **UCI Diabetes Dataset**  
  Predicts diabetes onset from patient lifestyle and demographic factors.

- **MIMIC-IV Dataset**  
  Predicts in-hospital mortality using ICU time-series data.

---

## 📁 Directory Structure & Usage

This repository is organized to support experimentation across multiple LUPI-based learning paradigms.

```bash
CSC494_PRIVILEGED_INFORMATION/
├── data/                # Preprocessing scripts for each pattern (Direct, Multitask, etc.)
├── model/               # Model definitions for each pattern and training strategy
├── prompting/           # LLM-generated side information and pairwise similarity data
├── img/                 # Visualizations (optional)
├── utils.py             # Shared utilities (grid search, run_experiments function)
├── direct.py            # Train using Direct pattern
├── multitask.py         # Train using Multi-task pattern
├── multiview.py         # Train using Multi-view pattern
├── pairwise.py          # Train using Pairwise similarity pattern
├── explore_data.py      # Exploratory data analysis
└── *.csv                # Results files for each pattern
```

---

## 🚀 Getting Started

Install all dependencies:

```bash
pip install -r requirements.txt
```

---

## ⚙️ File Roles & Execution Guide

data/
    Contains dataset preprocessing modules tailored to each learning pattern:
    - baseline_data.py
    - direct_data.py
    - multitask_data.py
    - multiview_data.py
    - pairwise_data.py

model/
    Implements model architectures specific to each integration pattern and training regime:
    - Direct (with/without residuals or decompression)
    - Multi-task with attention-based heads
    - Multi-view dual-encoder models
    - Pairwise MLP similarity models

utils.py
    Provides shared functionality:
    - grid_search: performs hyperparameter search over validation set
    - run_experiments: executes 10 randomized training iterations for robust evaluation


